{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMGdicu8PVD9"
      },
      "source": [
        "# Video understanding with Gemini 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbKkL5ksQYq1"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "source": [
        "model_name = \"gemini-2.0-flash-exp\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sgbw9krwPmo"
      },
      "source": [
        "### System instructions\n",
        "\n",
        " With the new SDK, the `system_instructions` and the `model` parameters must be passed in all `generate_content` calls, so let's save them to not have to type them all the time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GBdoMUVwP6j"
      },
      "outputs": [],
      "source": [
        "system_instructions = \"\"\"\n",
        "    When given a video and a query, call the relevant function only once with the appropriate timecodes and text for the video\n",
        "  \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMcwUw48vL1N"
      },
      "outputs": [],
      "source": [
        "# Load sample images\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4 -O Pottery.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/Jukin_Trailcam_Videounderstanding.mp4 -O Trailcam.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4 -O Post_its.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/user_study.mp4 -O User_study.mp4 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUUMJ4kE0OZS",
        "outputId": "89137c63-ddbb-42d0-dbaa-c130bde7fbc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/xckrl6d7e1ig\n",
            "Waiting for video to be processed.\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/6xfarr3jjyb7\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/9w56qgq4godt\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/1svtqex47rn6\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(path=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + video_file.uri)\n",
        "\n",
        "  return video_file\n",
        "\n",
        "pottery_video = upload_video('Pottery.mp4')\n",
        "trailcam_video = upload_video('Trailcam.mp4')\n",
        "post_its_video = upload_video('Post_its.mp4')\n",
        "user_study_video = upload_video('User_study.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAa7sCD7tuMW"
      },
      "source": [
        "# Search within videos\n",
        "\n",
        "First, try using the model to search within your videos and describe all the animal sightings in the trailcam video.\n",
        "\n",
        "<video controls width=\"500\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/Jukin_Trailcam_Videounderstanding.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZw41-lsKKMf",
        "outputId": "b6a0726f-cc29-4ad3-aefa-e4eae9cacb69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n[\n  {\n    \"timecode\": \"0:00\",\n    \"caption\": \"A close-up shot shows light brown fur with a dark spot.\"\n  },\n    {\n    \"timecode\": \"0:00\",\n    \"caption\": \"A fox is walking through a rocky area with trees. The audio includes an animal call, possibly a fox.\"\n  },\n  {\n    \"timecode\": \"0:03\",\n    \"caption\":\"Two foxes are walking and sniffing around a rocky area.\"\n  },\n  {\n    \"timecode\": \"0:10\",\n    \"caption\":\"Two foxes continue walking around the rocky area. One climbs on the rock.\"\n    \n  },\n    {\n    \"timecode\":\"0:16\",\n    \"caption\":\"A mountain lion with glowing eyes walks through a wooded area during a black and white scene.\"\n  },\n  {\n    \"timecode\": \"0:34\",\n    \"caption\": \"Two foxes with glowing eyes are digging and moving around.\"\n  },\n    {\n     \"timecode\":\"0:50\",\n     \"caption\":\"A very bright white shot is quickly followed by two foxes interacting.\"\n   },\n   {\n     \"timecode\":\"0:53\",\n     \"caption\":\"A fox and a mountain lion with glowing eyes walks near rocks in the dark.\"\n   },\n  {\n    \"timecode\":\"1:05\",\n    \"caption\": \"A mountain lion with glowing eyes walks among rocks at night.\"\n  },\n     {\n    \"timecode\":\"1:17\",\n      \"caption\":\"A mountain lion with glowing eyes walks near rocks with another mountain lion in the background.\"\n  },\n      {\n      \"timecode\":\"1:29\",\n       \"caption\":\"A bobcat with glowing eyes walks through a wooded area at night.\"\n   },\n     {\n    \"timecode\": \"1:51\",\n    \"caption\": \"A large dark brown bear walks through a wooded area.\"\n  },\n {\n    \"timecode\":\"1:56\",\n    \"caption\": \"A mountain lion with glowing eyes walks in the woods during a black and white scene.\"\n  },\n    {\n    \"timecode\":\"2:04\",\n     \"caption\":\"A close up shows the fur of a bear.\"\n   },\n  {\n     \"timecode\":\"2:07\",\n     \"caption\":\"A bear walks and turns while a younger bear sniffs at the ground in front of it.\"\n   },\n  {\n    \"timecode\":\"2:23\",\n    \"caption\": \"A fox with glowing eyes looks down at the lights of a city at night.\"\n  },\n      {\n       \"timecode\":\"2:35\",\n      \"caption\":\"A large bear with glowing eyes walks on rocks at night as a city is seen in the background.\"\n     },\n    {\n    \"timecode\":\"2:52\",\n     \"caption\":\"A mountain lion with glowing eyes looks at a rock.\"\n  },\n   {\n    \"timecode\":\"3:04\",\n    \"caption\": \"A large black bear walks through a wooded area during the day.\"\n  },\n   {\n     \"timecode\":\"3:22\",\n      \"caption\": \"A lighter brown bear looks around in a wooded area.\"\n   },\n     {\n       \"timecode\":\"3:27\",\n       \"caption\": \"A brown bear is sniffing at the ground with another one nearby.\"\n      },\n      {\n      \"timecode\":\"3:30\",\n      \"caption\": \"Two brown bears are seen from behind.\"\n       },\n       {\n       \"timecode\":\"3:37\",\n       \"caption\":\"A brown bear looks up.\"\n        },\n        {\n        \"timecode\":\"3:44\",\n       \"caption\":\"Two bears are sniffing at the ground.\"\n        },\n        {\n        \"timecode\":\"3:52\",\n       \"caption\":\"A brown bear sits and looks around.\"\n          },\n         {\n         \"timecode\":\"4:01\",\n         \"caption\":\"A group of three bears are walking through a wooded area.\"\n        },\n      {\n     \"timecode\":\"4:22\",\n        \"caption\":\"A bobcat with glowing eyes sits and looks around in a dark wooded area at night.\"\n   },\n    {\n       \"timecode\":\"4:47\",\n        \"caption\":\"A fox with glowing eyes walks around in a dark wooded area at night.\"\n   },\n      {\n         \"timecode\":\"4:56\",\n         \"caption\":\"A mountain lion with glowing eyes sniffs at something on the ground.\"\n      }\n]\n```"
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "prompt = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\"  # @param [\"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\", \"Organize all scenes from this video in a table, along with timecode, a short description, a list of objects visible in the scene (with representative emojis) and an estimation of the level of excitement on a scale of 1 to 10\"] {\"allow-input\":true}\n",
        "\n",
        "video = trailcam_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=video.uri,\n",
        "                    mime_type=video.mime_type),\n",
        "                ]),\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wog32E7CKnT6"
      },
      "source": [
        "# Extract and organize text\n",
        "\n",
        "Gemini can also read what's in the video and extract it in an organized way. You can even use Gemini reasoning capabilities to generate new ideas for you.\n",
        "\n",
        "<video controls width=\"400\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baNCeA3GKrfu",
        "outputId": "74bc3591-746b-4c6c-e00b-ecd85721ed06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Certainly! Here's the transcription of the sticky notes organized into a table, along with a few additional project name ideas:\n\n**Brainstorm Project Name Ideas**\n\n| Category           | Project Name Ideas                |\n|-------------------|-----------------------------------|\n| **Constellations** | Canis Major, Leo Minor, Lyra, Orion's Belt, Sagitta, Delphinus, Centaurus |\n| **Celestial Events** | Lunar Eclipse, Comets Tail, Supernova Echo,  Celestial Drift    |\n| **Cosmic Structures**| Stellar Nexus,  Andromeda's Reach, Galactic Core, Chaos Field,  |\n| **Math & Physics** | Symmetry, Golden Ratio, Infinity Loop, Taylor Series, Stokes Theorem, Fractal, Bayes Theorem, Riemann's Hypothesis, Chaos Theory, Euler's Path, Equilibrium|\n| **Mythology**   |  Astral Forge,   Prometheus Rising, Chimera Dream,  Perseus Shield, Zephyr, Titan, Odin, Aether, Phoenix, Athena's Eye, Athena, Hera, Cerberus, Medusa |\n| **Other**   |   Convergence, Lynx, Draco, Vector, Pandora's Box, Echo |\n| **Additional** | Aurora Borealis,  Cosmic Web, Quantum Leap, Nebula Dance, Event Horizon, Singularity, Galactic Symphony |\n\nI hope this is helpful! Let me know if you have any more questions!"
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "prompt = \"Transcribe the sticky notes, organize them and put it in a table. Can you come up with a few more ideas?\" # @param [\"Transcribe the sticky notes, organize them and put it in a table. Can you come up with a few more ideas?\", \"Which of those names who fit an AI product that can resolve complex questions using its thinking abilities?\"] {\"allow-input\":true}\n",
        "\n",
        "video = post_its_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=video.uri,\n",
        "                    mime_type=video.mime_type),\n",
        "                ]),\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjKIsLDMTNk1"
      },
      "source": [
        "# Structure information\n",
        "\n",
        "Gemini 2.0 is not only able to read text but also to reason and structure about real world objects. Like in this video about a display of ceramics with handwritten prices and notes.\n",
        "\n",
        "<video controls width=\"500\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqzqedMFT5Wp",
        "outputId": "be18c79f-7502-41cb-cee6-a7c2321d3870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here is the table of items and notes you have displayed:\n\n| Item              | Description                   | Height   | Diameter  | Price   | Notes                     |\n|-------------------|-------------------------------|----------|-----------|---------|---------------------------|\n| Tumblers        |  #5 Artichoke double dip | 4\"      | 3\"       | \\$20      |  -ish                     |\n| Small Bowls      |                         | 3.5\"   | 6.5\"       | \\$35     |                             |\n| Medium Bowls     |                        | 4\"      | 7\"       | \\$40      |                             |\n| Swatch #6        | #6 gemini double dip        | N/A    |   N/A      | N/A    |   SLOW COOL           |"
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "prompt = \"Give me a table of my items and notes\" # @param [\"Give me a table of my items and notes\", \"Help me come up with a selling pitch for my potteries\"] {\"allow-input\":true}\n",
        "\n",
        "video = pottery_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=video.uri,\n",
        "                    mime_type=video.mime_type),\n",
        "                ]),\n",
        "        prompt,\n",
        "    ],\n",
        "    config = types.GenerateContentConfig(\n",
        "        system_instruction=\"Don't forget to escape the dollar signs\",\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIfsFC0pVUTD"
      },
      "source": [
        "# Analyze screen recordings for key moments\n",
        "\n",
        "You can also use the model to analyze screen recordings. Let's say you're doing user studies on how people use your product, so you end up with lots of screen recordings, like this one, that you have to manually comb through.\n",
        "With just one prompt, the model can describe all the actions in your video.\n",
        "\n",
        "<video controls width=\"400\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/user_study.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrMHZ0MxW75y",
        "outputId": "c3f21f84-a0be-40b1-bf2a-97b6d9ef6912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Certainly! Here is a paragraph summarizing the video:\n\nThe video demonstrates a garden app with a list of plants available for purchase (0:00).  The user likes several plants by tapping on the \"Like\" button next to the plant names, including a Rose Plant, Fern, Cactus, and Hibiscus (0:10-0:27). The user adds a Fern, Cactus, and Hibiscus to their cart (0:13-0:25). After these additions, the user views the shopping cart to see all added items and their total cost (0:31), and then the user views their profile which shows how many plants they have liked and added to their cart (0:34). Later, the user navigates back to the home screen (0:37) and likes some more plants, and adds an orchid to the cart (0:38-0:44)."
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "prompt = \"Generate a paragraph that summarizes this video. Keep it to 3 to 5 sentences with corresponding timecodes.\" # @param [\"Generate a paragraph that summarizes this video. Keep it to 3 to 5 sentences with corresponding timecodes.\", \"Choose 5 key shots from this video and put them in a table with the timecode, text description of 10 words or less, and a list of objects visible in the scene (with representative emojis).\", \"Generate bullet points for the video. Place each bullet point into an object with the timecode of the bullet point in the video.\"] {\"allow-input\":true}\n",
        "\n",
        "video = user_study_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=video.uri,\n",
        "                    mime_type=video.mime_type),\n",
        "                ]),\n",
        "        prompt,\n",
        "    ],\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}